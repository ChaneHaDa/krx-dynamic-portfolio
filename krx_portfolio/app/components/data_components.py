"""
ë°ì´í„° ê´€ë¦¬ ê´€ë ¨ Streamlit ì»´í¬ë„ŒíŠ¸ë“¤
"""

import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Any, Tuple
import json


def render_data_status(data_info: Dict[str, Any]) -> None:
    """ë°ì´í„° ìƒíƒœ ì •ë³´ ë Œë”ë§"""
    st.subheader("ğŸ“Š ë°ì´í„° í˜„í™©")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric(
            label="ì´ ì¢…ëª© ìˆ˜",
            value=f"{data_info.get('total_stocks', 0):,}ê°œ",
            help="ì²˜ë¦¬ ê°€ëŠ¥í•œ ì „ì²´ ì¢…ëª© ìˆ˜"
        )
    
    with col2:
        last_update = data_info.get('last_update', 'Unknown')
        if isinstance(last_update, str):
            try:
                last_update = pd.to_datetime(last_update).strftime('%Y-%m-%d')
            except:
                pass
        
        st.metric(
            label="ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸",
            value=last_update,
            help="ë°ì´í„° ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸ ì¼ì"
        )
    
    with col3:
        data_period = data_info.get('data_period', {})
        start_date = data_period.get('start', 'N/A')
        end_date = data_period.get('end', 'N/A')
        
        st.metric(
            label="ë°ì´í„° ê¸°ê°„",
            value=f"{start_date} ~ {end_date}",
            help="ë³´ìœ  ë°ì´í„°ì˜ ì‹œì‘ì¼ê³¼ ì¢…ë£Œì¼"
        )
    
    with col4:
        st.metric(
            label="ë°ì´í„° í’ˆì§ˆ",
            value=f"{data_info.get('quality_score', 0):.1f}%",
            help="ë°ì´í„° ì™„ì„±ë„ ë° í’ˆì§ˆ ì ìˆ˜"
        )


def render_etl_controls() -> Dict[str, Any]:
    """ETL íŒŒì´í”„ë¼ì¸ ì œì–´ ì¸í„°í˜ì´ìŠ¤ ë Œë”ë§"""
    st.subheader("ğŸ”„ ETL íŒŒì´í”„ë¼ì¸ ì œì–´")
    
    # ETL ì„¤ì • íŒ¨ë„
    with st.expander("âš™ï¸ ETL ì„¤ì •", expanded=False):
        col1, col2 = st.columns(2)
        
        with col1:
            data_root = st.text_input(
                "ë°ì´í„° ë£¨íŠ¸ ê²½ë¡œ",
                value="/path/to/krx/data",
                help="KRX JSON ë°ì´í„°ê°€ ì €ì¥ëœ ë£¨íŠ¸ ë””ë ‰í† ë¦¬"
            )
            
            start_date = st.date_input(
                "ì‹œì‘ì¼",
                value=datetime(2020, 1, 1),
                help="ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘ì¼"
            )
        
        with col2:
            end_date = st.date_input(
                "ì¢…ë£Œì¼",
                value=datetime.now(),
                help="ë°ì´í„° ìˆ˜ì§‘ ì¢…ë£Œì¼"
            )
            
            force_reload = st.checkbox(
                "ê°•ì œ ì¬ë¡œë“œ",
                value=False,
                help="ìºì‹œ ë¬´ì‹œí•˜ê³  ì „ì²´ ë°ì´í„° ë‹¤ì‹œ ë¡œë“œ"
            )
    
    # ETL ì‹¤í–‰ ë²„íŠ¼
    col1, col2, col3 = st.columns([1, 2, 1])
    
    with col2:
        if st.button("ğŸš€ ETL íŒŒì´í”„ë¼ì¸ ì‹¤í–‰", type="primary", use_container_width=True):
            etl_config = {
                "data_root": data_root,
                "start_date": start_date.strftime('%Y-%m-%d'),
                "end_date": end_date.strftime('%Y-%m-%d'),
                "force_reload": force_reload
            }
            
            return etl_config
    
    return {}


def render_cache_management(cache_info: Dict[str, Any]) -> None:
    """ìºì‹œ ê´€ë¦¬ ì¸í„°í˜ì´ìŠ¤ ë Œë”ë§"""
    st.subheader("ğŸ’¾ ìºì‹œ ê´€ë¦¬")
    
    # ìºì‹œ í˜„í™©
    col1, col2, col3 = st.columns(3)
    
    with col1:
        cache_size = cache_info.get('total_size', 0)
        if cache_size > 1024**3:  # GB
            size_str = f"{cache_size / 1024**3:.2f} GB"
        elif cache_size > 1024**2:  # MB
            size_str = f"{cache_size / 1024**2:.2f} MB"
        else:  # KB
            size_str = f"{cache_size / 1024:.2f} KB"
        
        st.metric("ì´ ìºì‹œ í¬ê¸°", size_str)
    
    with col2:
        st.metric("ìºì‹œ íŒŒì¼ ìˆ˜", f"{cache_info.get('file_count', 0):,}ê°œ")
    
    with col3:
        last_cleared = cache_info.get('last_cleared', 'Never')
        st.metric("ë§ˆì§€ë§‰ ì •ë¦¬", last_cleared)
    
    # ìºì‹œ ë””ë ‰í† ë¦¬ë³„ ìƒì„¸ ì •ë³´
    if 'directories' in cache_info:
        st.markdown("**ğŸ“ ë””ë ‰í† ë¦¬ë³„ ìºì‹œ í˜„í™©**")
        
        cache_dirs = []
        for dir_name, dir_info in cache_info['directories'].items():
            cache_dirs.append({
                "ë””ë ‰í† ë¦¬": dir_name,
                "íŒŒì¼ ìˆ˜": f"{dir_info.get('count', 0):,}ê°œ",
                "í¬ê¸°": f"{dir_info.get('size', 0) / 1024**2:.1f} MB",
                "ë§ˆì§€ë§‰ ìˆ˜ì •": dir_info.get('last_modified', 'Unknown')
            })
        
        if cache_dirs:
            st.dataframe(pd.DataFrame(cache_dirs), hide_index=True, use_container_width=True)
    
    # ìºì‹œ ê´€ë¦¬ ë²„íŠ¼ë“¤
    st.markdown("**ğŸ› ï¸ ìºì‹œ ê´€ë¦¬ ì‘ì—…**")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        if st.button("ğŸ—‘ï¸ ì „ì²´ ì‚­ì œ", help="ëª¨ë“  ìºì‹œ íŒŒì¼ì„ ì‚­ì œí•©ë‹ˆë‹¤"):
            st.warning("âš ï¸ ì „ì²´ ìºì‹œê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ìŒ ì‹¤í–‰ ì‹œ ì „ì²´ ë°ì´í„°ë¥¼ ë‹¤ì‹œ ë¡œë“œí•©ë‹ˆë‹¤.")
    
    with col2:
        if st.button("ğŸ§¹ ì˜¤ë˜ëœ íŒŒì¼ë§Œ", help="7ì¼ ì´ìƒ ëœ ìºì‹œ íŒŒì¼ë§Œ ì‚­ì œ"):
            st.info("ğŸ“… 7ì¼ ì´ìƒ ëœ ìºì‹œ íŒŒì¼ì´ ì •ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    with col3:
        if st.button("ğŸ“Š ìºì‹œ í†µê³„", help="ìƒì„¸í•œ ìºì‹œ ì‚¬ìš© í†µê³„ë¥¼ í‘œì‹œ"):
            show_cache_statistics(cache_info)
    
    with col4:
        if st.button("ğŸ” ìºì‹œ ê²€ì¦", help="ìºì‹œ íŒŒì¼ ë¬´ê²°ì„±ì„ ê²€ì¦"):
            st.success("âœ… ìºì‹œ íŒŒì¼ ê²€ì¦ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")


def show_cache_statistics(cache_info: Dict[str, Any]) -> None:
    """ìºì‹œ í†µê³„ ìƒì„¸ í‘œì‹œ"""
    with st.expander("ğŸ“Š ìºì‹œ ìƒì„¸ í†µê³„", expanded=True):
        
        # íŒŒì¼ í˜•íƒœë³„ í†µê³„
        if 'file_types' in cache_info:
            st.markdown("**ğŸ“„ íŒŒì¼ í˜•íƒœë³„ ë¶„í¬**")
            
            file_types_df = pd.DataFrame([
                {"í˜•íƒœ": ext, "ê°œìˆ˜": info['count'], "í¬ê¸°(MB)": info['size'] / 1024**2}
                for ext, info in cache_info['file_types'].items()
            ])
            
            st.bar_chart(file_types_df.set_index('í˜•íƒœ')['ê°œìˆ˜'])
        
        # ì‹œê°„ë³„ ì‚¬ìš© íŒ¨í„´
        if 'usage_pattern' in cache_info:
            st.markdown("**â° ì‹œê°„ë³„ ì‚¬ìš© íŒ¨í„´**")
            
            usage_df = pd.DataFrame(cache_info['usage_pattern'])
            st.line_chart(usage_df.set_index('hour')['access_count'])


def render_data_quality_report(quality_data: Dict[str, Any]) -> None:
    """ë°ì´í„° í’ˆì§ˆ ë¦¬í¬íŠ¸ ë Œë”ë§"""
    st.subheader("âœ… ë°ì´í„° í’ˆì§ˆ ë¦¬í¬íŠ¸")
    
    # ì „ì²´ í’ˆì§ˆ ì ìˆ˜
    overall_score = quality_data.get('overall_score', 0)
    score_color = "green" if overall_score >= 90 else "orange" if overall_score >= 70 else "red"
    
    st.markdown(f"### ì „ì²´ í’ˆì§ˆ ì ìˆ˜: <span style='color:{score_color}'>{overall_score:.1f}%</span>", unsafe_allow_html=True)
    
    # ì„¸ë¶€ í’ˆì§ˆ ì§€í‘œ
    quality_metrics = quality_data.get('metrics', {})
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        completeness = quality_metrics.get('completeness', 0)
        st.metric("ì™„ì „ì„±", f"{completeness:.1f}%", help="ê²°ì¸¡ê°’ì´ ì—†ëŠ” ë°ì´í„°ì˜ ë¹„ìœ¨")
    
    with col2:
        accuracy = quality_metrics.get('accuracy', 0)
        st.metric("ì •í™•ì„±", f"{accuracy:.1f}%", help="ì˜¬ë°”ë¥¸ í˜•ì‹ì˜ ë°ì´í„° ë¹„ìœ¨")
    
    with col3:
        consistency = quality_metrics.get('consistency', 0)
        st.metric("ì¼ê´€ì„±", f"{consistency:.1f}%", help="ì¼ê´€ëœ í¬ë§·ì˜ ë°ì´í„° ë¹„ìœ¨")
    
    with col4:
        timeliness = quality_metrics.get('timeliness', 0)
        st.metric("ì ì‹œì„±", f"{timeliness:.1f}%", help="ìµœì‹  ë°ì´í„°ì˜ ë¹„ìœ¨")
    
    # í’ˆì§ˆ ì´ìŠˆ ëª©ë¡
    if 'issues' in quality_data and quality_data['issues']:
        st.markdown("**âš ï¸ ë°œê²¬ëœ í’ˆì§ˆ ì´ìŠˆ**")
        
        for issue in quality_data['issues']:
            severity = issue.get('severity', 'info').lower()
            icon = "ğŸ”´" if severity == 'high' else "ğŸŸ¡" if severity == 'medium' else "ğŸ”µ"
            
            st.markdown(f"{icon} **{issue.get('type', 'Unknown')}**: {issue.get('description', 'No description')}")
            
            if issue.get('affected_records', 0) > 0:
                st.markdown(f"   - ì˜í–¥ë°›ì€ ë ˆì½”ë“œ: {issue['affected_records']:,}ê°œ")
    else:
        st.success("âœ… í’ˆì§ˆ ì´ìŠˆê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")


def render_etl_progress(progress_data: Dict[str, Any]) -> None:
    """ETL ì§„í–‰ ìƒí™© ë Œë”ë§"""
    if not progress_data:
        return
    
    st.subheader("â³ ETL ì§„í–‰ ìƒí™©")
    
    # ì „ì²´ ì§„í–‰ë¥ 
    overall_progress = progress_data.get('overall_progress', 0)
    st.progress(overall_progress, f"ì „ì²´ ì§„í–‰ë¥ : {overall_progress:.1%}")
    
    # ë‹¨ê³„ë³„ ì§„í–‰ ìƒí™©
    stages = progress_data.get('stages', {})
    
    for stage_name, stage_info in stages.items():
        col1, col2 = st.columns([3, 1])
        
        with col1:
            stage_progress = stage_info.get('progress', 0)
            st.progress(stage_progress, f"{stage_name}: {stage_progress:.1%}")
        
        with col2:
            status = stage_info.get('status', 'pending')
            status_emoji = "âœ…" if status == 'completed' else "ğŸ”„" if status == 'running' else "â³"
            st.markdown(f"{status_emoji} {status}")
    
    # ë¡œê·¸ ë©”ì‹œì§€
    if 'logs' in progress_data:
        with st.expander("ğŸ“ ìƒì„¸ ë¡œê·¸"):
            for log_entry in progress_data['logs'][-10:]:  # ìµœê·¼ 10ê°œë§Œ í‘œì‹œ
                timestamp = log_entry.get('timestamp', '')
                message = log_entry.get('message', '')
                level = log_entry.get('level', 'info').upper()
                
                level_color = {
                    'ERROR': 'red',
                    'WARNING': 'orange', 
                    'INFO': 'blue',
                    'DEBUG': 'gray'
                }.get(level, 'black')
                
                st.markdown(f"<span style='color:{level_color}'>[{timestamp}] {level}: {message}</span>", unsafe_allow_html=True)


def render_data_preview(data_sample: pd.DataFrame, title: str = "ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°") -> None:
    """ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° ë Œë”ë§"""
    if data_sample.empty:
        st.warning("í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    st.subheader(f"ğŸ‘€ {title}")
    
    # ë°ì´í„° ê¸°ë³¸ ì •ë³´
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("í–‰ ìˆ˜", f"{len(data_sample):,}")
    
    with col2:
        st.metric("ì—´ ìˆ˜", f"{len(data_sample.columns):,}")
    
    with col3:
        memory_usage = data_sample.memory_usage(deep=True).sum() / 1024**2
        st.metric("ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰", f"{memory_usage:.1f} MB")
    
    # ë°ì´í„° í…Œì´ë¸” (ìƒìœ„ Nê°œ í–‰ë§Œ í‘œì‹œ)
    display_rows = min(100, len(data_sample))
    st.dataframe(
        data_sample.head(display_rows),
        use_container_width=True
    )
    
    if len(data_sample) > display_rows:
        st.info(f"ğŸ“ ìƒìœ„ {display_rows}ê°œ í–‰ë§Œ í‘œì‹œë©ë‹ˆë‹¤. (ì „ì²´: {len(data_sample):,}ê°œ)")
    
    # ë°ì´í„° íƒ€ì… ì •ë³´
    with st.expander("ğŸ“‹ ë°ì´í„° íƒ€ì… ì •ë³´"):
        dtype_info = pd.DataFrame({
            "ì»¬ëŸ¼": data_sample.columns,
            "ë°ì´í„° íƒ€ì…": data_sample.dtypes.astype(str),
            "ê²°ì¸¡ê°’": data_sample.isnull().sum(),
            "ê²°ì¸¡ê°’ ë¹„ìœ¨(%)": (data_sample.isnull().sum() / len(data_sample) * 100).round(2)
        })
        
        st.dataframe(dtype_info, hide_index=True, use_container_width=True)